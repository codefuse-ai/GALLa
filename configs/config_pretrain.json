{
  "data_dir": "path_to_pretrain_data",
  "node_type_embedding": "node_type_embedding.pth",
  "output_dir": "output/qwen2.5-coder-1.5b",
  "tb_dir": "output/tb/qwen2.5-coder-1.5b",
  "pretrained_model_path": "qwen2.5-coder-1.5b",
  "model_type": "qwen2.5",
  "mode": "pt",
  "graph_token_num": 256,
  "graph_hidden_dim": 1024,
  "data_split": "99.5,0.5",
  "per_device_train_batch_size": 1,
  "per_device_eval_batch_size": 1,
  "learning_rate": 1e-5,
  "min_lr": 1e-6,
  "weight_decay": 0.1,
  "gradient_accumulation_steps": 1,
  "lr_scheduler_type": "cosine",
  "num_warmup_steps": 1000,
  "num_train_epochs": 50,
  "seed": 42,
  "seq_length": 4096,
  "log_interval": 10,
  "checkpointing_steps": 1000,
  "evaluation_steps": 1000,
  "epoch_checkpointing": true,
  "early_stopping": false,
  "early_stopping_stall_num": 15
}
